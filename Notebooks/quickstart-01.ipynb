{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8310b4ba-4bd6-4887-be9e-d5ce9d50cb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As the moonlight sparkled over the sleepy town, Dog Man curled up with his trusty sidekick, Petey the Cat, dreaming of new adventures where good always triumphed over evil.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"Write a one-sentence bedtime story about DogMan comic character\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5032d1-0431-47e2-ac3c-01ddc2545f17",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "The response from the model is more complicated than what is shown above. Most importantly, it will contain a \"output\" property which will have an array of items generated by the model (when applicable). However, we can simplify our consumption of this output (When supported), using \"output_text\" property , a derived property which can be accessed using the response object as shown above.\n",
    "\n",
    "Let us examine the entire response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb624b72-cec5-47ed-9f7f-da4738e54615",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "created_at": 1742434853,
       "error": null,
       "id": "resp_67db7225950c8192a33c2f3ad43d39f6031c2da8925b84ac",
       "incomplete_details": null,
       "instructions": null,
       "max_output_tokens": null,
       "metadata": {},
       "model": "gpt-4o-mini-2024-07-18",
       "object": "response",
       "output": [
        {
         "content": [
          {
           "annotations": [],
           "text": "As the moonlight sparkled over the sleepy town, Dog Man curled up with his trusty sidekick, Petey the Cat, dreaming of new adventures where good always triumphed over evil.",
           "type": "output_text"
          }
         ],
         "id": "msg_67db7227dd6c8192b290543f6513c7fc031c2da8925b84ac",
         "role": "assistant",
         "status": "completed",
         "type": "message"
        }
       ],
       "parallel_tool_calls": true,
       "previous_response_id": null,
       "reasoning": {
        "effort": null,
        "generate_summary": null
       },
       "status": "completed",
       "store": true,
       "temperature": 1,
       "text": {
        "format": {
         "type": "text"
        }
       },
       "tool_choice": "auto",
       "tools": [],
       "top_p": 1,
       "truncation": "disabled",
       "usage": {
        "input_tokens": 37,
        "input_tokens_details": {
         "cached_tokens": 0
        },
        "output_tokens": 40,
        "output_tokens_details": {
         "reasoning_tokens": 0
        },
        "total_tokens": 77
       },
       "user": null
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, JSON\n",
    "\n",
    "response_json = response.model_dump_json() #convert the response to a dictionary\n",
    "display(JSON(response_json))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c429126d-b470-4170-b11c-e09e42a7f405",
   "metadata": {},
   "source": [
    "Inorder to specify roles in your messages to the model, similar to the chat completions, we can use some special properties in our input to the model.\n",
    "\n",
    "**special properties**\n",
    "\n",
    "**instructions:** set this property to inform the system on how to behave or act as\n",
    "\n",
    "**input** set this property to the actual query you want to ask the llm engine\n",
    "\n",
    "following is a example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6691fa5c-bdb1-4a0c-b805-e0bf9f3f9897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, eating five sundaes a day is generally not healthy. While they can be a fun treat occasionally, they are often high in sugar, calories, and fats, which can lead to health issues like weight gain, dental problems, and increased risk of chronic diseases if consumed regularly. Itâ€™s important to enjoy treats in moderation and balance them with nutritious foods. How about we find some healthier dessert options to try together?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"Act like a parent\",\n",
    "    input=\"Is eating 5 sundaes a day bad?\",\n",
    "    max_output_tokens = 200\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe35701-1a11-4259-8040-4a0e39513513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
